
In this example, we can tell the baby_names.csv file is in the same directory as where the spark-shell script was launched.

*********************************

val baby_names = sqlContext.read.format("Baby_Names__Beginning_2007.csv").option("header", "true").option("inferSchema", "true")

baby_names: org.apache.spark.sql.DataFrame = [Year: int, First Name: string, County: string, Sex: string, Count: int]

**************Register a temp table************

baby_names.registerTempTable("names")

******************We’re now ready to query using SQL such as finding the distinct years in the CSV**********************

val distinctYears = sqlContext.sql("select distinct Year from names")


distinctYears.collect.foreach(println)


*********It might be handy to know the schema

baby_names.printSchema


*****************************


Spark SQL CSV Example Tutorial Part 2
But, let’s try some more advanced SQL, such as determining the names which appear most often in the data


val popular_names = sqlContext.sql("select distinct(`First Name`), count(County) as cnt from names group by `First Name` order by cnt desc LIMIT 10")
popular_names.collect.foreach(println)

val popular_names = sqlContext.sql("select distinct(`First Name`), sum(Count) as cnt from names group by `First Name` order by cnt desc LIMIT 10")
popular_names.collect.foreach(println)





